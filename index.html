<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />

    <title>Keren Gruteke Klein</title>

    <meta name="author" content="Keren Gruteke Klein" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon" />
    <link rel="stylesheet" type="text/css" href="stylesheet.css" />

    <style>
      /* small enhancements if stylesheet.css is missing */
      body { font-family: -apple-system, BlinkMacSystemFont, Segoe UI, Roboto, Helvetica, Arial, sans-serif; line-height: 1.5; color: #222; }
      a { color: #1772d0; text-decoration: none; }
      a:hover { text-decoration: underline; }
      .name { font-size: 32px; font-weight: 700; }
      .papertitle { font-weight: 600; }
      .highlight { background: #ffffd0; padding: 1px 4px; border-radius: 4px; }
      .tag { display: inline-block; font-size: 12px; padding: 2px 8px; border-radius: 999px; background: #eef3ff; color: #315bd6; margin-left: 6px; vertical-align: middle; }
      .subtle { color: #666; }
      .small { font-size: 12px; color: #666; }
    </style>
  </head>

  <body>
    <table style="width:100%;max-width:900px;border:0;border-spacing:0;border-collapse:separate;margin:0 auto;"><tbody>
      <tr><td style="padding:0">

        <!-- Header -->
        <table style="width:100%;border:0;border-spacing:0;border-collapse:separate;margin:0 auto;"><tbody>
          <tr>
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p class="name" style="text-align:center">Keren Gruteke Klein</p>
              <p>
                I'm a Direct-Track PhD student in Data Science at the <a href="https://www.technion.ac.il/">Technion</a>, advised by <a href="https://dds.technion.ac.il/people/academic-staff/yevgeni-berzak/">Yevgeni Berzak</a> in the <a href="https://lacclab.github.io/">LaCC Lab</a>.
              <p> 
              </p>
                My research lies at the intersection between <span class="highlight">Natural Language Processing</span> and <span class="highlight">Cognition</span>, focusing on cognitively driven readability and text simplification, and the generation of eye-movement scanpaths during reading.
              </p>
              <p>
                I co-develop <em>EyeBench</em>, a benchmark for predictive modeling from eye movements in reading.
              </p>
              <p style="text-align:center">
                <span>Email: gkeren[at]campus.technion.ac.il</span>
                &nbsp;/&nbsp;
                <a href="https://github.com/KerenGruteke">GitHub</a>
                &nbsp;/&nbsp;
                <a href="https://www.linkedin.com/in/keren-gruteke/">LinkedIn</a>
                &nbsp;/&nbsp;
                <a href="https://scholar.google.com/citations?user=eRv0rbYAAAAJ&hl=en">Scholar</a>
                &nbsp;/&nbsp;
                <a href="https://orcid.org/0009-0004-7942-4611">ORCID</a>
              </p>
            </td>
            <td style="padding:2.5%;width:37%;max-width:37%">
              <a href="images/KerenGrutekeKlein.jpg"><img alt="profile photo" src="images/KerenGrutekeKlein.jpg" style="width:100%;max-width:100%;object-fit:cover;border-radius:50%" /></a>
              <!-- <p class="small" style="text-align:center;margin-top:8px">Text</p> -->
            </td>
          </tr>
        </tbody></table>

        <!-- Research blurb -->
        <table style="width:100%;border:0;border-spacing:0;border-collapse:separate;margin:0 auto"><tbody>
          <tr>
            <td style="padding:16px;width:100%;vertical-align:middle">
              <h2>Publications</h2>
              <!--<p>I study eye movements in reading, readability, text simplification, and models for cognitive state decoding. I build models that combine gaze and text to understand reading behavior and to generate realistic scanpaths. Some projects below are <span class="highlight">highlighted</span>.</p>-->
            </td>
          </tr>
        </tbody></table>

        <!-- Publications (compact, academic-homepage style) -->
        <table style="width:100%;border:0;border-spacing:0 12px;border-collapse:separate;margin:0 auto"><tbody>

          <!-- Under review -->
          <tr onmouseout="pnas_stop()" onmouseover="pnas_start()">
            <td style="padding:16px;width:20%;vertical-align:middle">
              <div class="one">
                <div class="two" id="pnas_image"><img src="images/pnas_before.png" width="100%" /></div>
                <img src="images/pnas_before.png" width="100%" />
              </div>
              <script>
                function pnas_start(){ var e=document.getElementById('pnas_image'); if(e) e.style.opacity='1'; }
                function pnas_stop(){ var e=document.getElementById('pnas_image'); if(e) e.style.opacity='0'; }
                pnas_stop();
              </script>
            </td>

            <td style="padding:8px;width:80%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2502.11150">
                <span class="papertitle">Readability Formulas, Systems and LLMs are Poor Predictors of Reading Ease</span>
              </a>
              <br>
              <strong><a href="https://kerengrutekeklein.github.io/">K. Gruteke Klein</a></strong>, 
              S. Frenkel, 
              <a href="https://omershubi.github.io/">O. Shubi</a>, 
              <a href="https://dds.technion.ac.il/people/academic-staff/yevgeni-berzak/">Y. Berzak</a>
              <br>
              <em>Under review</em>, 2025
              <br>

              <!-- links -->
              <a href="https://arxiv.org/abs/2502.11150" class="btn">arXiv</a> /
              <a href="javascript:void(0)" onclick="showCite('pnas2025')" class="btn">Cite</a>

              <p class="subtle" style="margin:6px 0 0">
                Methods for scoring text readability have been studied for over a century, and are
widely used in research and in user-facing applications in many domains. Thus far,
the development and evaluation of such methods have primarily relied on two types of
offline behavioral data, performance on reading comprehension tests and ratings of text
readability levels. In this work, we instead focus on a fundamental and understudied
aspect of readability, real-time reading ease, captured with online reading measures
using eye tracking. We introduce an evaluation framework for readability scoring
methods which quantifies their ability to account for reading ease, while controlling
for content variation across texts. Applying this evaluation to prominent traditional
readability formulas, modern machine learning systems, frontier Large Language Models
and commercial systems used in education, suggests that they are all poor predictors
of reading ease in English. This outcome holds across native and non-native speakers,
reading regimes, and textual units of different lengths. The evaluation further reveals
that existing methods are often outperformed by word properties commonly used in
psycholinguistics for prediction of reading times. Our results highlight a fundamental
limitation of existing approaches to readability scoring, the utility of psycholinguistics
for readability research, and the need for new, cognitively driven readability scoring
approaches that can better account for reading ease.
              </p>

              <!-- hidden BibTeX citation -->
              <div id="cite-pnas2025" class="cite-box" style="display:none">
                <pre>@article{grutekeklein2025readability,
            title={Readability Formulas, Systems and LLMs are Poor Predictors of Reading Ease},
            author={Gruteke Klein, Keren and Frenkel, Shachar and Shubi, Omer and Berzak, Yevgeni},
            year={2025},
            note={under review},
            url={https://arxiv.org/abs/2502.11150}
          }</pre>
                <button onclick="hideCite('pnas2025')">Close</button>
              </div>
            </td>
          </tr>
          
          <!-- EyeBench (NeurIPS 2025) -->
          <tr onmouseout="eyebench_stop()" onmouseover="eyebench_start()" bgcolor="#ffffd0">
            <td style="padding:16px;width:20%;vertical-align:middle">
              <div class="one">
                <div class="two" id="eyebench_image">
                  <img src="images/eyebench_before.png" width="100%" />
                </div>
                <img src="images/eyebench_before.png" width="100%" />
              </div>
              <script>
                function eyebench_start(){ var e=document.getElementById('eyebench_image'); if(e) e.style.opacity='1'; }
                function eyebench_stop(){ var e=document.getElementById('eyebench_image'); if(e) e.style.opacity='0'; }
                eyebench_stop();
              </script>
            </td>

            <td style="padding:8px;width:80%;vertical-align:middle">
              <a href="https://eyebench.github.io/">
                <span class="papertitle">EyeBench: Predictive Modeling from Eye Movements in Reading</span>
              </a>
              <br>
              <a href="https://omershubi.github.io/">O. Shubi</a>, 
              <a href="https://www.cl.uzh.ch/en/research-groups/digital-linguistics/people/lab-members/reich.html">D. R. Reich</a>, 
              <strong><a href="https://kerengrutekeklein.github.io/">K. Gruteke Klein</a></strong>, 
              <a href="http://www.linkedin.com/in/yuval-angel-74346a1a4">Y. Angel</a>, 
              <a href="https://www.uni-potsdam.de/de/cs-ml/staff/phd/prasse">P. Prasse</a>, 
              <a href="https://www.cl.uzh.ch/en/research-groups/digital-linguistics/people/group-leader/jaeger.html">L. A. Jäger</a>, 
              <a href="https://dds.technion.ac.il/people/academic-staff/yevgeni-berzak/">Y. Berzak</a>
              <br>
              <em>NeurIPS</em>, 2025 <span class="tag">Benchmark</span>
              <br>

              <!-- links -->
              <a href="https://eyebench.github.io/" class="btn">project page</a> /
              <!-- <a href="https://arxiv.org/abs/2510.00000" class="btn">arXiv</a> / -->
              <a href="javascript:void(0)" onclick="showCite('eyebench')" class="btn">Cite</a>

              <p class="subtle" style="margin:6px 0 0">
                We present EyeBench, the first benchmark designed to evaluate machine learning
models that decode cognitive and linguistic information from eye movements
during reading. EyeBench offers an accessible entry point to the challenging and
underexplored domain of modeling eye tracking data paired with text, aiming to
foster innovation at the intersection of multimodal AI and cognitive science. The
benchmark provides a standardized evaluation framework for predictive models,
covering a diverse set of datasets and tasks, ranging from assessment of reading
comprehension to detection of developmental dyslexia. Progress on the EyeBench
challenge will pave the way for both practical real-world applications, such as
adaptive user interfaces and personalized education, and scientific advances in
understanding human language processing. The benchmark is released as an opensource software package which includes data downloading and harmonization
scripts, baselines and state-of-the-art models, as well as evaluation code, publicly
available at https://github.com/EyeBench/eyebench.
              </p>

              <!-- hidden BibTeX citation -->
              <div id="cite-eyebench" class="cite-box" style="display:none">
                <pre>@inproceedings{shubieyebench,
            title={EyeBench: Predictive Modeling from Eye Movements in Reading},
            author={Shubi, Omer and Reich, David Robert and Gruteke Klein, Keren and Angel, Yuval and Prasse, Paul and J{\"a}ger, Lena Ann and Berzak, Yevgeni},
            booktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems Datasets and Benchmarks Track}
          }</pre>
                <button onclick="hideCite('eyebench')">Close</button>
              </div>
            </td>
          </tr>

          <script>
          function showCite(id){ document.getElementById('cite-'+id).style.display='block'; }
          function hideCite(id){ document.getElementById('cite-'+id).style.display='none'; }
          </script>


          <!-- CogSci 2025 -->
          <tr onmouseout="cogsci_stop()" onmouseover="cogsci_start()" bgcolor="#ffffd0">
            <td style="padding:16px;width:20%;vertical-align:middle">
              <div class="one">
                <div class="two" id="cogsci_image"><img src="images/cogsci_before.png" width="100%" /></div>
                <img src="images/cogsci_before.png" width="100%" />
              </div>
              <script>
                function cogsci_start(){ var e=document.getElementById('cogsci_image'); if(e) e.style.opacity='1'; }
                function cogsci_stop(){ var e=document.getElementById('cogsci_image'); if(e) e.style.opacity='0'; }
                cogsci_stop();
              </script>
            </td>

            <td style="padding:8px;width:80%;vertical-align:middle">
              <a href="https://osf.io/preprints/psyarxiv/dhk8c_v2">
                <span class="papertitle">The Effect of Text Simplification on Reading Fluency and Reading Comprehension in L1 English Speakers</span>
              </a>
              <br>
              <strong><a href="https://kerengrutekeklein.github.io/">K. Gruteke Klein</a></strong>, 
              <a href="https://omershubi.github.io/">O. Shubi</a>, 
              S. Frenkel, 
              <a href="https://dds.technion.ac.il/people/academic-staff/yevgeni-berzak/">Y. Berzak</a>
              <br>
              <em>CogSci</em>, 2025 <span class="tag">Oral</span>
              <br>

              <!-- links -->
              <a href="https://osf.io/preprints/psyarxiv/dhk8c_v2" class="btn">paper</a> /
              <a href="javascript:void(0)" onclick="showCite('cogsci2025')" class="btn">Cite</a>

              <p class="subtle" style="margin:6px 0 0">
                Text simplification is a common practice for making texts easier to read and easier to understand. To which extent does it
achieve these goals, and which participant and text characteristics drive simplification benefits? In this work, we use eye
tracking to address these questions for the first time for the population of adult native (L1) English speakers. We find that 42%
of the readers exhibit reading facilitation effects, while only
2% improve reading comprehension accuracy. We further observe that reading fluency benefits are larger for slower and less
experienced readers, while comprehension benefits are more
substantial in lower comprehension readers, but not vice versa.
Finally, we find that high-complexity original texts are key for
enhancing reading fluency, while large complexity reduction is
more pertinent to improving comprehension. Our study highlights the potential of cognitive measures in the evaluation of
text simplification and distills empirically driven principles for
enhancing simplification effectiveness.
              </p>

              <!-- hidden BibTeX citation -->
              <div id="cite-cogsci2025" class="cite-box" style="display:none">
                <pre>@inproceedings{gruteke2025effect,
            title={The effect of text simplification on reading fluency and reading comprehension in L1 English speakers},
            author={Gruteke Klein, Keren and Shubi, Omer and Frenkel, Shachar and Berzak, Yevgeni},
            booktitle={Proceedings of the Annual Meeting of the Cognitive Science Society},
            volume={47},
            year={2025}
          }</pre>
                <button onclick="hideCite('cogsci2025')">Close</button>
              </div>
            </td>
          </tr>


          <!-- CoNLL 2024 -->
          <tr onmouseout="conll_stop()" onmouseover="conll_start()">
            <td style="padding:16px;width:20%;vertical-align:middle">
              <div class="one">
                <div class="two" id="conll_image"><img src="images/conll_before.png" width="100%" /></div>
                <img src="images/conll_before.png" width="100%" />
              </div>
              <script>
                function conll_start(){ var e=document.getElementById('conll_image'); if(e) e.style.opacity='1'; }
                function conll_stop(){ var e=document.getElementById('conll_image'); if(e) e.style.opacity='0'; }
                conll_stop();
              </script>
            </td>

            <td style="padding:8px;width:80%;vertical-align:middle">
              <a href="https://aclanthology.org/2024.conll-1.17/">
                <span class="papertitle">The Effect of Surprisal on Reading Times in Information Seeking and Repeated Reading</span>
              </a>
              <br>
              <strong><a href="https://kerengrutekeklein.github.io/">K. Gruteke Klein</a></strong>, 
              <a href="https://yoavmeiri.github.io/">Y. Meiri</a>, 
              <a href="https://omershubi.github.io/">O. Shubi</a>, 
              <a href="https://dds.technion.ac.il/people/academic-staff/yevgeni-berzak/">Y. Berzak</a>
              <br>
              <em>CoNLL</em>, 2024 <span class="tag">Oral</span> <span class="tag">20% acceptance</span>
              <br>

              <!-- links -->
              <a href="https://aclanthology.org/2024.conll-1.17/" class="btn">paper</a> /
              <a href="javascript:void(0)" onclick="showCite('conll2024')" class="btn">Cite</a>

              <p class="subtle" style="margin:6px 0 0">
                The effect of surprisal on processing difficulty
has been a central topic of investigation in psycholinguistics. Here, we use eyetracking data
to examine three language processing regimes
that are common in daily life but have not been
addressed with respect to this question: information seeking, repeated processing, and the
combination of the two. Using standard regimeagnostic surprisal estimates we find that the prediction of surprisal theory regarding the presence of a linear effect of surprisal on processing times, extends to these regimes. However,
when using surprisal estimates from regimespecific contexts that match the contexts and
tasks given to humans, we find that in information seeking, such estimates do not improve the
predictive power of processing times compared
to standard surprisals. Further, regime-specific
contexts yield near zero surprisal estimates with
no predictive power for processing times in repeated reading. These findings point to misalignments of task and memory representations
between humans and current language models,
and question the extent to which such models
can be used for estimating cognitively relevant
quantities. We further discuss theoretical challenges posed by these results.
              </p>

              <!-- hidden BibTeX citation -->
              <div id="cite-conll2024" class="cite-box" style="display:none">
                <pre>@inproceedings{klein-etal-2024-effect,
            title = {The Effect of Surprisal on Reading Times in Information Seeking and Repeated Reading},
            author = {Gruteke Klein, Keren and Meiri, Yoav and Shubi, Omer and Berzak, Yevgeni},
            editor = {Barak, Libby and Alikhani, Malihe},
            booktitle = {Proceedings of the 28th Conference on Computational Natural Language Learning},
            month = nov,
            year = {2024},
            address = {Miami, FL, USA},
            publisher = {Association for Computational Linguistics},
            url = {https://aclanthology.org/2024.conll-1.17/},
            doi = {10.18653/v1/2024.conll-1.17},
            pages = {219--230}
          }</pre>
                <button onclick="hideCite('conll2024')">Close</button>
              </div>
            </td>
          </tr>



        </tbody></table>

        <!-- Talks / Presentations (compact) -->
        <table style="width:100%;border:0;border-spacing:0;border-collapse:separate;margin:12px auto 0"><tbody>
          <tr>
            <td style="padding:16px;width:100%;vertical-align:middle">
              <h2>Talks & Presentations</h2>
              <ul style="margin-top:0">
                <li><strong>EyeBench</strong> — Poster at EurIPS 2025, Copenhagen.</li>
                <li><strong>Text Readability Measures Do Not Predict Reading Ease</strong> — Poster at CPL 2025, Utrecht.</li>
                <li><strong>Differences in Text Simplification Effects in L1 vs L2</strong> — Oral at IndiREAD 2025, Saarbrücken.</li>
                <li><strong>Text Simplification Effects on Reading Fluency and Rading Comprehension</strong> — Oral at CogSci 2025, San Francisco (Hybrid) and at the Multipleye Workshop 2025, Stuttgart.</li>
                <li><strong>Surprisal & Reading Times</strong> — Oral at CoNLL 2024, Miami; Poster at ISCOL 2024, Haifa.</li>
              </ul>
            </td>
          </tr>
        </tbody></table>

        <!-- Short CV (academic-homepage compact style) -->
        <table style="width:100%;border:0;border-spacing:0;border-collapse:separate;margin:0 auto"><tbody>
          <tr>
            <td style="padding:16px;width:100%;vertical-align:top">
              <h2>Bio</h2>
              <p style="margin-top:0">
                <strong>Education.</strong>
                <ul style="margin-top:4px; margin-bottom:0;">
                  <li>PhD (Direct Track) in Data Science, Technion (Sep 2025–Present)</li>
                  <li>MSc (Direct Track) in Data Science, Technion (May 2024–Sep 2025), GPA 97.6</li>
                  <li>BSc in Data Science & Engineering, Technion (Oct 2020–Oct 2024)</li>
                </ul>
                <br/>
                <strong>Awards.</strong> VATAT Scholarship for Outstanding MSc Students.
                <br/>
                <strong>Industry.</strong> Data Scientist at Wiliot (2022–2024).
                <br/>
                <strong>Teaching.</strong>
                <ul style="margin-top:4px; margin-bottom:0;">
                  <li>TA, Language, Computation & Cognition (0960222)</li>
                  <li>TA, Cognition in Information Visualization (0960625)</li>
                  <li>TA, Intelligent Interactive Systems (00960235)</li>
                </ul>
              </p>
            </td>
          </tr>
        </tbody></table>

        <!-- <p class="small" style="text-align:center;margin:32px 0 10px">Last updated: Nov 2025 · Please see my <a href="/data/CV_Keren_Gruteke_Klein.pdf">CV</a> for details.</p> -->
        <p class="small" style="text-align:center;margin:32px 0 10px">
        Last updated: Nov 2025 · © Keren Gruteke Klein · Feel free to get in touch.
        </p>

      </td></tr>
    </tbody></table>
  </body>
</html>

